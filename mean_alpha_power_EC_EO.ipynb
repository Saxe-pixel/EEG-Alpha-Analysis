{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9156ea28",
   "metadata": {},
   "source": [
    "# Mean Alpha Power: EC vs EO (Top-K per class per subject)\n",
    "\n",
    "This notebook reproduces the **mean absolute** and **mean relative** alpha power analysis, but instead of selecting a single class/run (e.g. a longest EC run), it selects:\n",
    "\n",
    "- **Top-K EC epochs per subject**: highest `prob_ec`\n",
    "- **Top-K EO epochs per subject**: lowest `prob_ec`\n",
    "\n",
    "Key rules:\n",
    "- Default `K = 60` (configurable)\n",
    "- A subject is **excluded** unless it has **K distinct epochs for both EC and EO**\n",
    "- Results are cached so heavy computations are not repeated on reruns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9e754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import platform\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import mne\n",
    "from mne.time_frequency import psd_array_welch\n",
    "from scipy.interpolate import make_interp_spline\n",
    "from scipy import stats\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa36c178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Path configuration (New_EEG adaptation) --------------------\n",
    "# Pick which classifier run you want to analyze.\n",
    "# This should match a run folder under: <LABELING_ROOT>/preprocessed_setfiles/<RUN_FOLDER>/label_predictions.csv\n",
    "RUN_FOLDER = os.getenv(\n",
    "    'RUN_FOLDER',\n",
    "    'old_dataset__fooof__allch__cv2__time_align_conditions__one_main_fooof__mainfooof_all_epochs__pen_l2'\n",
    ")\n",
    "\n",
    "# Where Label_with_EC_EO_Classifier.ipynb wrote its predictions\n",
    "LABELING_ROOT = os.getenv('LABELING_ROOT', r'G:\\ChristianMusaeus\\labeling')\n",
    "\n",
    "# Metadata (age/sex/etc). Provide a path to metadata_time_filtered.csv.\n",
    "# Set to \"\" to disable metadata-dependent plots.\n",
    "METADATA_CSV = os.getenv('METADATA_CSV', r'G:\\ChristianMusaeus\\metadata_time_filtered.csv')\n",
    "\n",
    "# -------------------- Selection + computation configuration --------------------\n",
    "TOP_K_PER_CLASS = int(os.getenv('TOP_K_PER_CLASS', '60'))\n",
    "EXCLUDE_IF_MISSING_K = os.getenv('EXCLUDE_IF_MISSING_K', '1').strip() not in {'0','false','False'}\n",
    "FORCE_RECOMPUTE = os.getenv('FORCE_RECOMPUTE', '0').strip() in {'1','true','True'}\n",
    "\n",
    "# Alpha bands / PSD settings (match Project-main defaults)\n",
    "ABS_FMIN, ABS_FMAX = 8.0, 13.0\n",
    "REL_FMIN, REL_FMAX = 1.0, 40.0\n",
    "N_FFT = int(os.getenv('N_FFT', '200'))\n",
    "\n",
    "# ROI for occipital plots\n",
    "OCCIPITAL_ROI = ['O1', 'O2']\n",
    "\n",
    "# -------------------- Helpers --------------------\n",
    "\n",
    "def guess_project_root() -> Path:\n",
    "    p = Path.cwd().resolve()\n",
    "    for _ in range(8):\n",
    "        if (p / '.git').exists() or (p / 'New_EEG').exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    return Path.cwd().resolve()\n",
    "\n",
    "def is_wsl() -> bool:\n",
    "    try:\n",
    "        return 'microsoft' in platform.uname().release.lower()\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def resolve_windows_path(p: str) -> Path:\n",
    "    # Best-effort conversion of Windows drive paths when running on WSL.\n",
    "    s = str(p)\n",
    "    if is_wsl():\n",
    "        m = re.match(r'^([A-Za-z]):[\\/](.*)$', s)\n",
    "        if m:\n",
    "            drive = m.group(1).lower()\n",
    "            rest = m.group(2).replace('\\\\', '/')\n",
    "            return Path(f'/mnt/{drive}/{rest}')\n",
    "    return Path(s)\n",
    "\n",
    "project_root = guess_project_root()\n",
    "new_eeg_root = project_root / 'New_EEG'\n",
    "outputs_root = new_eeg_root / 'outputs'\n",
    "\n",
    "labeling_root = resolve_windows_path(LABELING_ROOT)\n",
    "if labeling_root.name.lower() == 'labeling':\n",
    "    labeling_root = labeling_root / 'preprocessed_setfiles'\n",
    "\n",
    "run_dir = labeling_root / RUN_FOLDER\n",
    "label_predictions_csv = run_dir / 'label_predictions.csv'\n",
    "if not label_predictions_csv.exists():\n",
    "    raise FileNotFoundError(f'Missing: {label_predictions_csv}')\n",
    "\n",
    "analysis_root = outputs_root / 'analysis' / 'mean_alpha_power_EC_EO' / f\"{RUN_FOLDER}__topk{TOP_K_PER_CLASS}\"\n",
    "analysis_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "selected_cache = analysis_root / f\"selected_epochs_topk{TOP_K_PER_CLASS}.csv.gz\"\n",
    "metrics_cache = analysis_root / f\"alpha_metrics_topk{TOP_K_PER_CLASS}.csv.gz\"\n",
    "\n",
    "metadata_path = None\n",
    "if str(METADATA_CSV).strip():\n",
    "    metadata_path = resolve_windows_path(METADATA_CSV)\n",
    "    if not metadata_path.exists():\n",
    "        raise FileNotFoundError(f'METADATA_CSV does not exist: {metadata_path}')\n",
    "\n",
    "print('Run dir:', run_dir)\n",
    "print('Label predictions:', label_predictions_csv)\n",
    "print('Analysis outputs:', analysis_root)\n",
    "print('Selected cache:', selected_cache)\n",
    "print('Metrics cache:', metrics_cache)\n",
    "print('Metadata:', metadata_path if metadata_path else '<not set>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2c394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_str(x) -> str:\n",
    "    return '' if pd.isna(x) else str(x).strip()\n",
    "\n",
    "def compute_prob_ec(df: pd.DataFrame) -> pd.Series:\n",
    "    # Prefer explicit prob_ec if present\n",
    "    if 'prob_ec' in df.columns:\n",
    "        return pd.to_numeric(df['prob_ec'], errors='coerce')\n",
    "\n",
    "    # Otherwise infer from (Label, Probability)\n",
    "    # Probability is probability of the predicted label.\n",
    "    if 'Label' in df.columns and 'Probability' in df.columns:\n",
    "        label = pd.to_numeric(df['Label'], errors='coerce')\n",
    "        p = pd.to_numeric(df['Probability'], errors='coerce')\n",
    "        return np.where(label == 1, p, 1.0 - p)\n",
    "\n",
    "    raise KeyError('Need either prob_ec, or (Label + Probability) columns to compute prob_ec')\n",
    "\n",
    "def load_epochs_any(path_str: str):\n",
    "    p = resolve_windows_path(path_str)\n",
    "    suf = p.suffix.lower()\n",
    "    if suf == '.set':\n",
    "        return mne.io.read_epochs_eeglab(str(p), verbose='ERROR')\n",
    "    return mne.read_epochs(str(p), verbose='ERROR')\n",
    "\n",
    "def canonical_channel_name(ch_name: str) -> str:\n",
    "    name = str(ch_name).strip()\n",
    "    name = re.sub(r'^EEG\\s+', '', name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r'-REF$', '', name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r'\\s+', '', name)\n",
    "    return name\n",
    "\n",
    "def get_occipital_picks(epochs, roi=None) -> np.ndarray:\n",
    "    roi = roi or OCCIPITAL_ROI\n",
    "    roi_set = {c.upper() for c in roi}\n",
    "    ch_can = [canonical_channel_name(ch).upper() for ch in epochs.ch_names]\n",
    "    picks = [i for i, n in enumerate(ch_can) if n in roi_set]\n",
    "    return np.asarray(picks, dtype=int)\n",
    "\n",
    "def select_topk_epochs_per_subject(df_sub: pd.DataFrame, k: int) -> pd.DataFrame:\n",
    "    # Returns rows with columns: epoch_idx, prob_ec, class\n",
    "    d = df_sub.copy()\n",
    "    d = d.dropna(subset=['epoch_idx','prob_ec'])\n",
    "    d['epoch_idx'] = pd.to_numeric(d['epoch_idx'], errors='coerce').astype('Int64')\n",
    "    d = d.dropna(subset=['epoch_idx'])\n",
    "    d['epoch_idx'] = d['epoch_idx'].astype(int)\n",
    "\n",
    "    d = d.sort_values('prob_ec', ascending=True)\n",
    "    if len(d) < 2*k:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    eo = d.head(k).copy()\n",
    "    ec = d.tail(k).copy()\n",
    "\n",
    "    if set(eo['epoch_idx']).intersection(set(ec['epoch_idx'])):\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    eo['class'] = 'EO'\n",
    "    ec['class'] = 'EC'\n",
    "    out = pd.concat([eo, ec], ignore_index=True)\n",
    "    return out[['epoch_idx','prob_ec','class']]\n",
    "\n",
    "def abs_alpha_uV2_perHz(selected_data: np.ndarray, sfreq: float, fmin: float, fmax: float, n_fft: int) -> float:\n",
    "    psds, _ = psd_array_welch(\n",
    "        selected_data,\n",
    "        sfreq=float(sfreq),\n",
    "        fmin=float(fmin),\n",
    "        fmax=float(fmax),\n",
    "        n_fft=int(n_fft),\n",
    "        verbose=False,\n",
    "    )\n",
    "    mean_power_per_channel = psds.mean(axis=-1)          # (epochs, channels)\n",
    "    mean_power_over_epochs = mean_power_per_channel.mean(axis=0)  # (channels,)\n",
    "    return float(np.nanmean(mean_power_over_epochs)) * 1e12\n",
    "\n",
    "def relative_alpha(selected_data: np.ndarray, sfreq: float) -> float:\n",
    "    psds_alpha, _ = psd_array_welch(\n",
    "        selected_data,\n",
    "        sfreq=float(sfreq),\n",
    "        fmin=float(ABS_FMIN),\n",
    "        fmax=float(ABS_FMAX),\n",
    "        n_fft=int(N_FFT),\n",
    "        verbose=False,\n",
    "    )\n",
    "    alpha_power = float(np.nanmean(psds_alpha.sum(axis=-1)))\n",
    "\n",
    "    psds_total, _ = psd_array_welch(\n",
    "        selected_data,\n",
    "        sfreq=float(sfreq),\n",
    "        fmin=float(REL_FMIN),\n",
    "        fmax=float(REL_FMAX),\n",
    "        n_fft=int(N_FFT),\n",
    "        verbose=False,\n",
    "    )\n",
    "    total_power = float(np.nanmean(psds_total.sum(axis=-1)))\n",
    "\n",
    "    if total_power == 0 or np.isnan(total_power):\n",
    "        return float('nan')\n",
    "    return alpha_power / total_power\n",
    "\n",
    "def compute_ci_bounds(mean: float, std: float, n: int) -> tuple[float, float]:\n",
    "    if n < 2 or not np.isfinite(std):\n",
    "        return mean, mean\n",
    "    se = std / np.sqrt(n)\n",
    "    try:\n",
    "        t = float(stats.t.ppf(0.975, df=int(n-1)))\n",
    "    except Exception:\n",
    "        t = 1.96\n",
    "    return mean - t*se, mean + t*se\n",
    "\n",
    "def prepare_age_stats(df: pd.DataFrame, value_col: str, age_col: str = 'age') -> pd.DataFrame:\n",
    "    d = df.copy()\n",
    "    d = d.dropna(subset=[age_col, 'class', value_col])\n",
    "    d[age_col] = pd.to_numeric(d[age_col], errors='coerce')\n",
    "    d[value_col] = pd.to_numeric(d[value_col], errors='coerce')\n",
    "    d = d.replace([np.inf, -np.inf], np.nan).dropna(subset=[age_col, value_col])\n",
    "\n",
    "    stats_df = d.groupby([age_col, 'class']).agg(\n",
    "        Mean=(value_col, 'mean'),\n",
    "        Std=(value_col, 'std'),\n",
    "        N=(value_col, 'count'),\n",
    "    ).reset_index()\n",
    "\n",
    "    bounds = stats_df.apply(lambda r: compute_ci_bounds(float(r['Mean']), float(r['Std']) if pd.notna(r['Std']) else float('nan'), int(r['N'])), axis=1)\n",
    "    bounds_df = pd.DataFrame(bounds.tolist(), columns=['Lower','Upper'])\n",
    "    return pd.concat([stats_df, bounds_df], axis=1)\n",
    "\n",
    "def plot_age_curve(stats_df: pd.DataFrame, title: str, ylabel: str, out_path: Path, age_col: str = 'age'):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    palette = {'EC': 'tab:red', 'EO': 'tab:blue'}\n",
    "\n",
    "    for cls in ['EC', 'EO']:\n",
    "        g = stats_df[stats_df['class'] == cls].sort_values(age_col)\n",
    "        if len(g) == 0:\n",
    "            continue\n",
    "\n",
    "        x = g[age_col].to_numpy(dtype=float)\n",
    "        y = g['Mean'].to_numpy(dtype=float)\n",
    "        lo = g['Lower'].to_numpy(dtype=float)\n",
    "        hi = g['Upper'].to_numpy(dtype=float)\n",
    "\n",
    "        # Ensure strictly increasing x for spline\n",
    "        order = np.argsort(x)\n",
    "        x, y, lo, hi = x[order], y[order], lo[order], hi[order]\n",
    "        x_unique, idx = np.unique(x, return_index=True)\n",
    "        x, y, lo, hi = x_unique, y[idx], lo[idx], hi[idx]\n",
    "\n",
    "        color = palette.get(cls, 'gray')\n",
    "        plt.scatter(x, y, color=color, s=20, alpha=0.8, label=f'{cls} mean')\n",
    "\n",
    "        if len(x) >= 3:\n",
    "            x_smooth = np.linspace(float(x.min()), float(x.max()), 1000)\n",
    "            k = int(min(5, max(1, len(x)-1)))\n",
    "            try:\n",
    "                spline_mean = make_interp_spline(x, y, k=k)\n",
    "                spline_lo = make_interp_spline(x, lo, k=k)\n",
    "                spline_hi = make_interp_spline(x, hi, k=k)\n",
    "                y_s = spline_mean(x_smooth)\n",
    "                lo_s = spline_lo(x_smooth)\n",
    "                hi_s = spline_hi(x_smooth)\n",
    "                plt.plot(x_smooth, y_s, color=color, linewidth=2, label=f'{cls} smoothed')\n",
    "                plt.fill_between(x_smooth, lo_s, hi_s, color=color, alpha=0.18)\n",
    "            except Exception:\n",
    "                plt.plot(x, y, color=color, linewidth=2, label=f'{cls} line')\n",
    "        else:\n",
    "            plt.plot(x, y, color=color, linewidth=2, label=f'{cls} line')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    seen = set()\n",
    "    uniq_h, uniq_l = [], []\n",
    "    for h, l in zip(handles, labels):\n",
    "        if l in seen:\n",
    "            continue\n",
    "        seen.add(l)\n",
    "        uniq_h.append(h)\n",
    "        uniq_l.append(l)\n",
    "    plt.legend(uniq_h, uniq_l, fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print('Saved:', out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df5e325",
   "metadata": {},
   "source": [
    "## Load predictions and select top-K epochs per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220f2102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions\n",
    "pred_df = pd.read_csv(label_predictions_csv)\n",
    "\n",
    "# Standardize key columns\n",
    "if 'Test subject ID' in pred_df.columns:\n",
    "    pred_df['subject_id'] = pred_df['Test subject ID'].apply(_to_str)\n",
    "elif 'subject_id' in pred_df.columns:\n",
    "    pred_df['subject_id'] = pred_df['subject_id'].apply(_to_str)\n",
    "else:\n",
    "    raise KeyError('Could not find subject id column (Test subject ID / subject_id)')\n",
    "\n",
    "if 'Epoch number' in pred_df.columns:\n",
    "    pred_df['epoch_idx'] = pred_df['Epoch number']\n",
    "elif 'epoch_idx' not in pred_df.columns:\n",
    "    raise KeyError('Could not find epoch index column (Epoch number / epoch_idx)')\n",
    "\n",
    "pred_df['prob_ec'] = compute_prob_ec(pred_df)\n",
    "\n",
    "# File path mapping (optional but preferred)\n",
    "if 'file' in pred_df.columns:\n",
    "    subject_file_map = pred_df.groupby('subject_id')['file'].first().to_dict()\n",
    "else:\n",
    "    subject_file_map = {}\n",
    "\n",
    "# Select epochs (cached)\n",
    "if selected_cache.exists() and not FORCE_RECOMPUTE:\n",
    "    selected_df = pd.read_csv(selected_cache, compression='gzip')\n",
    "    print(f'Loaded selected epochs cache: {selected_cache} | rows={len(selected_df)}')\n",
    "else:\n",
    "    rows = []\n",
    "    excluded = 0\n",
    "    for subject_id, df_sub in pred_df.groupby('subject_id'):\n",
    "        sel = select_topk_epochs_per_subject(df_sub[['epoch_idx','prob_ec']].assign(epoch_idx=df_sub['epoch_idx'], prob_ec=df_sub['prob_ec']), TOP_K_PER_CLASS)\n",
    "        if len(sel) == 0:\n",
    "            excluded += 1\n",
    "            continue\n",
    "        file_path = subject_file_map.get(subject_id, '')\n",
    "        sel = sel.copy()\n",
    "        sel['subject_id'] = subject_id\n",
    "        sel['file'] = file_path\n",
    "        rows.append(sel)\n",
    "\n",
    "    selected_df = pd.concat(rows, ignore_index=True) if rows else pd.DataFrame(columns=['subject_id','file','epoch_idx','prob_ec','class'])\n",
    "\n",
    "    # Enforce exclusion rule: must have K for both classes per subject\n",
    "    if EXCLUDE_IF_MISSING_K and len(selected_df) > 0:\n",
    "        counts = selected_df.groupby(['subject_id','class'])['epoch_idx'].nunique().unstack('class').fillna(0)\n",
    "        ok = counts[(counts.get('EC',0) >= TOP_K_PER_CLASS) & (counts.get('EO',0) >= TOP_K_PER_CLASS)].index\n",
    "        before = selected_df['subject_id'].nunique()\n",
    "        selected_df = selected_df[selected_df['subject_id'].isin(ok)].copy()\n",
    "        after = selected_df['subject_id'].nunique()\n",
    "        print(f'Excluded subjects missing K per class: {before-after} (kept {after})')\n",
    "\n",
    "    selected_df.to_csv(selected_cache, index=False, compression='gzip')\n",
    "    print(f'Saved selected epochs cache: {selected_cache} | rows={len(selected_df)} | excluded (initial)={excluded}')\n",
    "\n",
    "print('Selected subjects:', selected_df['subject_id'].nunique())\n",
    "print('Rows per class:')\n",
    "print(selected_df['class'].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b86957",
   "metadata": {},
   "source": [
    "## Compute alpha metrics (absolute + relative; all channels + occipital ROI)\n",
    "\n",
    "This step is cached to avoid recomputing PSDs on reruns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eade147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute alpha metrics per subject per class (cached)\n",
    "if metrics_cache.exists() and not FORCE_RECOMPUTE:\n",
    "    metrics_df = pd.read_csv(metrics_cache, compression='gzip')\n",
    "    print(f'Loaded metrics cache: {metrics_cache} | rows={len(metrics_df)}')\n",
    "else:\n",
    "    records = []\n",
    "    for subject_id, df_sub in selected_df.groupby('subject_id'):\n",
    "        file_path = df_sub['file'].iloc[0] if 'file' in df_sub.columns else ''\n",
    "        if not str(file_path).strip():\n",
    "            # fallback: try any file column in pred_df\n",
    "            cand = pred_df[pred_df['subject_id'] == subject_id].get('file')\n",
    "            file_path = cand.dropna().iloc[0] if cand is not None and len(cand.dropna()) else ''\n",
    "\n",
    "        if not str(file_path).strip():\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            epochs = load_epochs_any(str(file_path))\n",
    "        except Exception as e:\n",
    "            print(f'Could not load epochs for {subject_id}: {e}')\n",
    "            continue\n",
    "\n",
    "        picks_occ = get_occipital_picks(epochs, OCCIPITAL_ROI)\n",
    "        sfreq = float(epochs.info['sfreq'])\n",
    "\n",
    "        for cls in ['EC','EO']:\n",
    "            ep_idx = pd.to_numeric(df_sub[df_sub['class'] == cls]['epoch_idx'], errors='coerce').dropna().astype(int).unique()\n",
    "            if ep_idx.size != TOP_K_PER_CLASS:\n",
    "                continue\n",
    "\n",
    "            data = epochs.get_data()[ep_idx]\n",
    "\n",
    "            abs_all = abs_alpha_uV2_perHz(data, sfreq, ABS_FMIN, ABS_FMAX, N_FFT)\n",
    "            rel_all = relative_alpha(data, sfreq)\n",
    "\n",
    "            abs_occ = float('nan')\n",
    "            rel_occ = float('nan')\n",
    "            if picks_occ is not None and len(picks_occ) > 0:\n",
    "                data_occ = data[:, picks_occ, :]\n",
    "                abs_occ = abs_alpha_uV2_perHz(data_occ, sfreq, ABS_FMIN, ABS_FMAX, N_FFT)\n",
    "                rel_occ = relative_alpha(data_occ, sfreq)\n",
    "\n",
    "            records.append({\n",
    "                'subject_id': subject_id,\n",
    "                'class': cls,\n",
    "                'file': file_path,\n",
    "                'n_epochs': int(ep_idx.size),\n",
    "                'abs_all_uV2_perHz': abs_all,\n",
    "                'rel_all': rel_all,\n",
    "                'abs_occ_uV2_perHz': abs_occ,\n",
    "                'rel_occ': rel_occ,\n",
    "            })\n",
    "\n",
    "    metrics_df = pd.DataFrame.from_records(records)\n",
    "    metrics_df.to_csv(metrics_cache, index=False, compression='gzip')\n",
    "    print(f'Saved metrics cache: {metrics_cache} | rows={len(metrics_df)}')\n",
    "\n",
    "# Merge metadata when available\n",
    "if metadata_path is not None and len(metrics_df) > 0:\n",
    "    meta = pd.read_csv(metadata_path)\n",
    "    # Normalize expected columns\n",
    "    if 'subject_id' not in meta.columns:\n",
    "        # Try common alternatives\n",
    "        for c in ['Subject_ID','SubjectID','Test subject ID']:\n",
    "            if c in meta.columns:\n",
    "                meta['subject_id'] = meta[c]\n",
    "                break\n",
    "    if 'age' not in meta.columns:\n",
    "        if 'Age' in meta.columns:\n",
    "            meta['age'] = meta['Age']\n",
    "        elif 'Y' in meta.columns:\n",
    "            meta['age'] = meta['Y']\n",
    "    if 'sex' not in meta.columns:\n",
    "        if 'Sex' in meta.columns:\n",
    "            meta['sex'] = meta['Sex']\n",
    "\n",
    "    meta['subject_id'] = meta['subject_id'].apply(_to_str)\n",
    "    metrics_df['subject_id'] = metrics_df['subject_id'].apply(_to_str)\n",
    "\n",
    "    metrics_df = metrics_df.merge(meta[['subject_id'] + [c for c in ['age','sex'] if c in meta.columns]], on='subject_id', how='left')\n",
    "\n",
    "print(metrics_df.head())\n",
    "print('Subjects in metrics:', metrics_df['subject_id'].nunique() if len(metrics_df) else 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027b3e00",
   "metadata": {},
   "source": [
    "## Plots\n",
    "\n",
    "All plots below are produced **for both classes** (EC and EO) using the cached `metrics_df`.\n",
    "\n",
    "Note on units:\n",
    "- Absolute alpha power is reported in **µV²/Hz**.\n",
    "- Relative alpha power is unitless (alpha-band power / total 1–40 Hz power).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a856e827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plots (included subjects only)\n",
    "if metadata_path is None or 'age' not in metrics_df.columns:\n",
    "    print('Metadata not available; skipping age/sex distribution plots.')\n",
    "else:\n",
    "    included = metrics_df[['subject_id','age','sex']].drop_duplicates('subject_id').copy()\n",
    "    included['age'] = pd.to_numeric(included['age'], errors='coerce')\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.hist(included['age'].dropna(), bins=20, color='gray', alpha=0.8)\n",
    "    plt.title('Age distribution (included subjects)')\n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel('Count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if 'sex' in included.columns:\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        included['sex'] = included['sex'].astype(str)\n",
    "        counts = included['sex'].value_counts(dropna=False)\n",
    "        plt.bar(counts.index.astype(str), counts.values, color='steelblue', alpha=0.85)\n",
    "        plt.title('Sex distribution (included subjects)')\n",
    "        plt.xlabel('Sex')\n",
    "        plt.ylabel('Count')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad17e0ac",
   "metadata": {},
   "source": [
    "## Mean alpha power vs age (EC and EO together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee93b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute alpha vs age (all channels)\n",
    "if metadata_path is None or 'age' not in metrics_df.columns:\n",
    "    print('Metadata not available; skipping age plots.')\n",
    "else:\n",
    "    abs_all_stats = prepare_age_stats(metrics_df, 'abs_all_uV2_perHz', age_col='age')\n",
    "    plot_age_curve(\n",
    "        abs_all_stats,\n",
    "        title='Mean Absolute Alpha Power vs. Age (All Channels) with 95% CI',\n",
    "        ylabel='Mean Absolute Alpha Power (µV²/Hz)',\n",
    "        out_path=analysis_root / 'abs_alpha_all_channels_vs_age.png',\n",
    "        age_col='age',\n",
    "    )\n",
    "\n",
    "# Relative alpha vs age (all channels)\n",
    "if metadata_path is not None and 'age' in metrics_df.columns:\n",
    "    rel_all_stats = prepare_age_stats(metrics_df, 'rel_all', age_col='age')\n",
    "    plot_age_curve(\n",
    "        rel_all_stats,\n",
    "        title='Mean Relative Alpha Power vs. Age (All Channels) with 95% CI',\n",
    "        ylabel='Mean Relative Alpha Power (alpha / 1–40 Hz)',\n",
    "        out_path=analysis_root / 'rel_alpha_all_channels_vs_age.png',\n",
    "        age_col='age',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e7364f",
   "metadata": {},
   "source": [
    "## Mean alpha power vs age by sex (EC and EO together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47213cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots by sex (two panels: Female/Male), each showing EC + EO\n",
    "\n",
    "def plot_by_sex(value_col: str, title: str, ylabel: str, out_name: str):\n",
    "    if metadata_path is None or 'age' not in metrics_df.columns or 'sex' not in metrics_df.columns:\n",
    "        print('Metadata not available; skipping sex plots.')\n",
    "        return\n",
    "\n",
    "    d = metrics_df.dropna(subset=['age','sex', value_col, 'class']).copy()\n",
    "    d['age'] = pd.to_numeric(d['age'], errors='coerce')\n",
    "    d[value_col] = pd.to_numeric(d[value_col], errors='coerce')\n",
    "    d = d.replace([np.inf, -np.inf], np.nan).dropna(subset=['age', value_col])\n",
    "\n",
    "    sexes = [s for s in ['Female','Male'] if s in set(d['sex'].astype(str))]\n",
    "    if not sexes:\n",
    "        sexes = sorted(d['sex'].astype(str).unique())[:2]\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(sexes), figsize=(16, 5), sharey=True)\n",
    "    if len(sexes) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    palette = {'EC': 'tab:red', 'EO': 'tab:blue'}\n",
    "\n",
    "    for ax, sex in zip(axes, sexes):\n",
    "        ds = d[d['sex'].astype(str) == str(sex)]\n",
    "        stats_df = prepare_age_stats(ds, value_col, age_col='age')\n",
    "\n",
    "        for cls in ['EC','EO']:\n",
    "            g = stats_df[stats_df['class'] == cls].sort_values('age')\n",
    "            if len(g) == 0:\n",
    "                continue\n",
    "\n",
    "            x = g['age'].to_numpy(dtype=float)\n",
    "            y = g['Mean'].to_numpy(dtype=float)\n",
    "            lo = g['Lower'].to_numpy(dtype=float)\n",
    "            hi = g['Upper'].to_numpy(dtype=float)\n",
    "\n",
    "            order = np.argsort(x)\n",
    "            x, y, lo, hi = x[order], y[order], lo[order], hi[order]\n",
    "            x_u, idx = np.unique(x, return_index=True)\n",
    "            x, y, lo, hi = x_u, y[idx], lo[idx], hi[idx]\n",
    "\n",
    "            color = palette.get(cls, 'gray')\n",
    "            ax.scatter(x, y, color=color, s=18, alpha=0.8)\n",
    "\n",
    "            if len(x) >= 3:\n",
    "                xs = np.linspace(float(x.min()), float(x.max()), 800)\n",
    "                k = int(min(5, max(1, len(x)-1)))\n",
    "                try:\n",
    "                    sm = make_interp_spline(x, y, k=k)\n",
    "                    slo = make_interp_spline(x, lo, k=k)\n",
    "                    shi = make_interp_spline(x, hi, k=k)\n",
    "                    ax.plot(xs, sm(xs), color=color, linewidth=2, label=cls)\n",
    "                    ax.fill_between(xs, slo(xs), shi(xs), color=color, alpha=0.18)\n",
    "                except Exception:\n",
    "                    ax.plot(x, y, color=color, linewidth=2, label=cls)\n",
    "            else:\n",
    "                ax.plot(x, y, color=color, linewidth=2, label=cls)\n",
    "\n",
    "        ax.set_title(str(sex))\n",
    "        ax.set_xlabel('Age')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    axes[0].set_ylabel(ylabel)\n",
    "    handles, labels = axes[-1].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='upper right')\n",
    "    fig.suptitle(title)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    out_path = analysis_root / out_name\n",
    "    fig.savefig(out_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print('Saved:', out_path)\n",
    "\n",
    "plot_by_sex('abs_all_uV2_perHz', 'Mean Absolute Alpha Power vs. Age by Sex (All Channels)', 'Mean Absolute Alpha Power (µV²/Hz)', 'abs_alpha_all_by_sex.png')\n",
    "plot_by_sex('rel_all', 'Mean Relative Alpha Power vs. Age by Sex (All Channels)', 'Mean Relative Alpha Power (alpha / 1–40 Hz)', 'rel_alpha_all_by_sex.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b485529",
   "metadata": {},
   "source": [
    "## Occipital ROI plots (O1/O2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8888d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Occipital ROI (O1/O2): absolute + relative vs age\n",
    "if metadata_path is None or 'age' not in metrics_df.columns:\n",
    "    print('Metadata not available; skipping occipital age plots.')\n",
    "else:\n",
    "    abs_occ_stats = prepare_age_stats(metrics_df, 'abs_occ_uV2_perHz', age_col='age')\n",
    "    plot_age_curve(\n",
    "        abs_occ_stats,\n",
    "        title='Mean Absolute Alpha Power vs. Age (Occipital ROI) with 95% CI',\n",
    "        ylabel='Mean Absolute Alpha Power (µV²/Hz)',\n",
    "        out_path=analysis_root / 'abs_alpha_occipital_vs_age.png',\n",
    "        age_col='age',\n",
    "    )\n",
    "\n",
    "    rel_occ_stats = prepare_age_stats(metrics_df, 'rel_occ', age_col='age')\n",
    "    plot_age_curve(\n",
    "        rel_occ_stats,\n",
    "        title='Mean Relative Alpha Power vs. Age (Occipital ROI) with 95% CI',\n",
    "        ylabel='Mean Relative Alpha Power (alpha / 1–40 Hz)',\n",
    "        out_path=analysis_root / 'rel_alpha_occipital_vs_age.png',\n",
    "        age_col='age',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b35166",
   "metadata": {},
   "source": [
    "## EC vs EO direct comparison (paired per subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a11f9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EC vs EO direct comparison (paired per subject)\n",
    "\n",
    "def plot_ec_vs_eo(value_col: str, title: str, xlabel: str, ylabel: str, out_name: str):\n",
    "    wide = metrics_df.pivot_table(index='subject_id', columns='class', values=value_col, aggfunc='mean')\n",
    "    wide = wide.dropna(subset=['EC','EO'])\n",
    "    if len(wide) == 0:\n",
    "        print('No paired EC/EO data available for', value_col)\n",
    "        return\n",
    "\n",
    "    x = wide['EO'].to_numpy(dtype=float)\n",
    "    y = wide['EC'].to_numpy(dtype=float)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(x, y, s=18, alpha=0.75)\n",
    "    lo = float(np.nanmin([x.min(), y.min()]))\n",
    "    hi = float(np.nanmax([x.max(), y.max()]))\n",
    "    plt.plot([lo, hi], [lo, hi], color='gray', linestyle='--', linewidth=1)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    out_path = analysis_root / out_name\n",
    "    plt.savefig(out_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print('Saved:', out_path)\n",
    "\n",
    "    diff = y - x\n",
    "    print(f'N subjects: {len(diff)} | % EC>EO: {100*np.mean(diff>0):.1f}% | mean(EC-EO)={np.mean(diff):.4g}')\n",
    "\n",
    "plot_ec_vs_eo(\n",
    "    'abs_all_uV2_perHz',\n",
    "    title='EC vs EO: Absolute Alpha Power (All Channels)',\n",
    "    xlabel='EO mean absolute alpha (µV²/Hz)',\n",
    "    ylabel='EC mean absolute alpha (µV²/Hz)',\n",
    "    out_name='compare_abs_all_ec_vs_eo.png',\n",
    ")\n",
    "\n",
    "plot_ec_vs_eo(\n",
    "    'rel_all',\n",
    "    title='EC vs EO: Relative Alpha Power (All Channels)',\n",
    "    xlabel='EO mean relative alpha',\n",
    "    ylabel='EC mean relative alpha',\n",
    "    out_name='compare_rel_all_ec_vs_eo.png',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99a83bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
